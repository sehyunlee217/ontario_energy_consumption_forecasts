---
title: "Forecasts for Ontario Energy Consumption"
author: "Seunghyun(Joe) Lee"
format: html
editor: visual
execute:
  warning: false
  echo: false
  message: false
---

```{r}
library(tidyverse)
library(lubridate)
library(feasts)
library(dplyr)
library(fable)
library(tsibble)
library(viridis)
library(hrbrthemes)
library(eeptools)
library(forecast)

# Datasets
ontario_temps <- read_csv("data/tg_mean.csv")
newborns_kr <- ontario94_02 <- read_csv("data/HourlyDemands_1994-2002.csv")
ontario02_23 <- read_csv("data/ontario_electricity_demand.csv")
```

```{r}
# Tidy Data into tsibble with monthly demands
ontario02_23_ts <- ontario02_23 |> 
  select(date, hourly_demand) |> 
  group_by(date) |> 
  summarize(
    daily_demand = sum(hourly_demand),
  ) |> 
  mutate(
    Month = yearmonth(date)
  ) |> 
  group_by(Month) |> 
  summarize(
    monthly_demand = sum(daily_demand)
  ) |> 
  as_tsibble(index = Month) |> 
  mutate(
    # Normalize to MW
    monthly_demand = monthly_demand/1000
  ) |> 
  filter(Month < yearmonth("2023 April"))

ontario94_02_ts <- ontario94_02 |> 
  mutate(
    Month = str_split_i(DateTime, " ", 1),
    Day = str_split_i(DateTime, " ", 2),
    Year = str_split_i(DateTime, " ", 3),
  ) |> 
  mutate(
    time = str_c(Day, "-", Month, "-", Year)
  ) |> 
  mutate(
    Date = dmy(time)
  ) |> 
  group_by(Date) |> 
  summarize(
    daily_demand = sum(OntarioDemand),
  ) |> 
  mutate(
    Month = yearmonth(Date)
  ) |> 
  group_by(Month) |> 
  summarize(
    monthly_demand = sum(daily_demand)
  )|>
  drop_na(Month) |> 
  as_tsibble(index = Month)
  
ontario94_95_ts <- ontario94_02_ts |> 
  filter(Month < yearmonth("1996 Jan"))

ontario97_02_ts <- ontario94_02_ts |> 
  filter(Month > yearmonth("1996 Dec"))

ontario96_ts <- ontario94_02 |> 
  mutate(
    Year = str_split_i(DateTime, "/", 1),
    Month = str_split_i(DateTime, "/", 2),
    Day = str_split_i(str_split_i(DateTime, "/", 3), " ", 1)
  )|> 
  mutate(
    time = str_c(Day, "-", Month, "-", Year)
  ) |> 
  mutate(
    Date = dmy(time)
  ) |> 
  group_by(Date) |> 
  summarize(
    daily_demand = sum(OntarioDemand),
  ) |> 
  mutate(
    Month = yearmonth(Date)
  ) |> 
  group_by(Month) |> 
  summarize(
    monthly_demand = sum(daily_demand)
  )|>
  drop_na(Month) |> 
  as_tsibble(index = Month)

ontario94_02_merged_ts <- union_all(ontario94_95_ts, ontario96_ts)
ontario94_02_merged_ts <- union_all(ontario94_02_merged_ts, ontario97_02_ts)
ontario94_02_merged_ts <- union_all(ontario94_02_merged_ts, ontario02_23_ts)

ontario_monthly_demand <- ontario94_02_merged_ts

ontario_temps_ts <- ontario_temps |> 
  mutate(
    Month = yearmonth(time)
  ) |> 
  as_tsibble(index = Month) |> 
  filter(Month >= yearmonth("1994 Jan") & Month <= yearmonth("2023 March")) 
```



## Background

There have been many fluctuations in temperature of Ontario, with hotter summers and colder winters leading to increased energy use. As climate change continues to intensify, these temperature extremes are expected to become more frequent, directly impacting energy consumption patterns. Forecasts for Ontario’s energy use must account for these shifts in temperature to ensure accurate predictions and better resource management in the future.

## Historical Trends for Temperatures in Ontario



```{r}
ontario_temps_ts |> 
  ggplot(aes(x = Month))+ 
  geom_smooth(aes(y = ssp126_tg_mean_p10, color = "mean 10%"), ) + 
  geom_smooth(aes(y = ssp126_tg_mean_p50, color = "mean 50%")) + 
  geom_smooth(aes(y = ssp126_tg_mean_p90, color = "mean 90%")) + 
  scale_colour_manual(name="Historical Means", values=c("blue", "red", "green")) + 
  theme_ipsum() + 
  labs(title = "Historical Means for Ontario Temperature (1994 - 2023)",y = "Temperature (C)")

```



Visualizing historical temperatures for Ontario since 1994 reveals that the 10%, 50%, and 90% percentiles of temperature averages have all increased over the past 30 years.



```{r}

ontario_temps_ts <- ontario_temps_ts |> 
  rename(
    Temp = ssp126_tg_mean_p50
  ) |> 
  select(Month, Temp)

elec_demand <- ontario_temps_ts |> 
  left_join(ontario_monthly_demand, by = "Month")

elec_demand |> 
  model(stl = STL(Temp)) |> 
  components() |> 
  autoplot() + 
  theme_bw()

```



The decomposition of historical temperatures shows a **strong upward trend in temperatures, highlighting a clear increase over time**. In addition, the decomposition reveals **strong seasonality**, with consistent patterns of temperature variation throughout the year. Alongside these observations, **expert forecasts for future temperatures are widely available**, driven by extensive research from climate scientists using advanced models to predict future temperature trends and their impacts.

## Historical Data on Ontario Energy Consumptions



```{r}
elec_demand <- elec_demand |> 
  fill(monthly_demand)

elec_demand |> 
  model(stl = STL(monthly_demand)) |>  
  components() |> 
  autoplot() + 
  theme_bw()
```



The decomposition of energy consumption data reveals a **decreasing trend over time**, alongside a strong seasonal component that reflects regular fluctuations throughout the year. While forecasts can be generated based on historical data, it is important to account for temperature changes and any anomalies to ensure accuracy in predicting future energy demand.



```{r}
elec_demand |> 
  mutate(monthly_demand = monthly_demand/1e3) |> 
  ggplot(aes(x = Temp, y = monthly_demand)) + 
  geom_point() + 
  geom_smooth() +
  theme_ipsum() + labs(x = "Temperature (C)", y = "Monthly Energy Consumption (GW)")
```



In fact, examining the relationship between temperature and monthly energy consumption reveals that higher temperatures in the summer lead to increased energy use due to air conditioning, while colder winters also drive up consumption for heating. The scatterplot suggests a **non-linear relationship between temperature and energy demand**, suggesting that **historical temperature data could be a valuable predictor for forecasting future monthly energy consumption**.

## Model Selection for Temperature



```{r}
elec_demand_long <- elec_demand |> 
  pivot_longer(
    cols = c(monthly_demand, Temp),
    names_to = "Type",
    values_to = "Value"
    )

elec_demand_long |> 
  ggplot(aes(x = Month, y = Value)) + 
  geom_line() + 
  facet_grid(Type ~ ., scales = "free_y") +
  labs(title = "Comparison between monthly energy consumption and temperatures")

```



To forecast future monthly energy consumption, it is crucial to first generate temperature forecasts. We will use an ARIMA model for this purpose. One of the key assumptions of the ARIMA model, due to its Moving Average (MA) component, is that the data must be stationary. However, the historical temperature data displays strong seasonality, which violates stationarity. To address this, we will apply seasonal adjustments to the data in order to properly determine the parameters for the ARIMA model.

### ACF and PACF Plots for Temperature (Non-Adjusted)



```{r}
ontario_temps_ts |> 
  gg_tsdisplay(Temp, plot_type = 'partial') 
```



### ACF and PACF Plots for Temperature (Seasonaly-Adjusted)



```{r}
ontario_temps_ts |> 
  gg_tsdisplay(difference(Temp, 12), plot_type = 'partial') 
```



By examining the ACF plot for the seasonally adjusted series, we observe a **cut off at lag 4**, suggesting that the lag could be used for the **MA(4) terms in the non-seasonal component**. Additionally, the **strong negative spike at lag 12 indicates the presence of an MA(1) term in the seasonal component**.

In the PACF plot, there is a clear **indication at lag 1**, pointing to an **AR(1) term for the non-seasonal component**. Similarly, the **strong negative spike at lag 12 suggests an AR(1) term for the seasonal component**.

We can compare our selected model to the AutoARIMA model generated by the fable package, which aims to minimize the AICc in a greedy manner. Upon comparison, we find that our **custom model closely aligns with the optimal model produced by fable**. It’s important to note that our model is an ARIMA(1,0,4)(1,1,1), as we previously applied seasonal differencing. When comparing the two ARIMA models, **minimizing AICc and BIC is asympotically equivalent to Leave-one-out-Cross-Validation** (M.Stone, 1977), making AICc a valuable metric for model selection.



```{r}
ontario_temps_fit <- ontario_temps_ts |> 
  model(
    autoARIMA = ARIMA(Temp),
    ARIMA104111 = ARIMA(Temp ~ 1 + pdq(1,0,4) + PDQ(1,1,1)),
    )

ontario_temps_fit

glance(ontario_temps_fit) |> select(.model, AIC, AICc, BIC)
```



Preceding with our custom model, our ARIMA(1,0,4)(1,1,1) model can be written as follows with the Backshift notation:

$$
(1 - \phi_{1}B)(1 - \phi_{1}B^{12})(1- B^{12}) y_{t} = (1 + \theta_{1}B + \theta_{2}B^2 + \theta_{3}B^3 + \theta_{4}B^4)(1 + \theta_{1}B^{12})\epsilon_{t}
$$ Lastly, we can visualize the residuals and its distributions to check that they are normally distributed, alongside the Ljung-Box test. The Null hypothesis for the Ljung-Box test is that the residuals do not display autocorrelation with each other. Furthremore, the degrees of freedom for this test is equivalent to the number of variables used in the model (7). Therfore, if we want to fail to reject the Null hypothesis in order to confirm that our model captured the correlated data from the dataset.



```{r}
ontario_temps_fit |> select(ARIMA104111) |> gg_tsresiduals()

augment(ontario_temps_fit) |>
  filter(.model == "ARIMA104111") |>
  features(.innov, ljung_box, lag=24, dof=7)
```



Our p-value is 0.395 for the Ljung-Box test with a degree of freedom of 7; therefore, we conclude that the residuals are not autocorrelated, indicating that **this model is a good fit at the 95% confidence level**.

Therefore, using this model, we can generate future forecasts for Ontario's temperatures as follows.



```{r}
ontario_temps_fc_2years <- ontario_temps_fit |> 
  select(ARIMA104111) |>
  generate(h = 24) |> 
  rename(
    Temp = .sim
  ) |> 
  select(Month, Temp)

ontario_temps_fit |> 
  select(ARIMA104111) |> 
  forecast(h = 24) |> 
  autoplot(ontario_temps_ts) + 
  theme_ipsum() + 
  labs(title = "2 Year forecasts of Ontario Temperature", y = "Temperature (C)")
```



## Model Selection for Energy Consumption

Now, we can fit the monthly energy consumption of Onatrio using two models.

1.  ARIMA model solely based on historical data
2.  Dynamic Regression model : Utilizes Temperature as an explanatory variable with ARIMA errors

### ARIMA Model with historical data

For fitting the ARIMA model based on historical data, we will use AutoARIMA to select the most appropriate model.



```{r}
fit_auto_arima <- elec_demand |> 
  model(
    ARIMA(monthly_demand)
  )

fit_auto_arima
fc2 <- forecast(fit_auto_arima, ontario_temps_fc_2years) 

fc2 |> autoplot(elec_demand) + 
    theme_ipsum() + labs(x = "Temperature (C)", y = "Monthly Demand (MW)",  title ="2T Forecasts with ARIMA")

```



AutoARIMA suggests an ARIMA(2,0,1)(0,1,1) model, suggesting applying seasonal differencing and 2 AR and 2 MA components.

### Dynamic Regression model

### ACF and PACF Plots for Monthly Energy Consumption (Non-Adjusted)


```{r}
elec_demand |> 
  gg_tsdisplay(monthly_demand, plot_type = 'partial') 
```



### ACF and PACF Plots for Monthly Energy Consumption (Seasonally-Adjusted)


```{r}
elec_demand |> 
  gg_tsdisplay(difference(monthly_demand, 12), plot_type = 'partial') 
```



Similar to the interpretation for temperature, the **ACF plot shows a drop around lag 3, indicating an MA(3)** component, along with a **peak at lag 12 that suggests an SMA(1)** component. In the **PACF plot, we observe a drop around lag 2, pointing to an AR(2)** component, while the **spike at lag 12 indicates a SAR(1)** component.

Now, we will fit a dynamic regression model with temperatures being an extraneous variable. The following model can be written as below: 



```{r}
fit_dy_reg <- elec_demand |> 
  model(
    ARIMA(monthly_demand ~ 1 + Temp + pdq(2,0,3) + PDQ(1,1,1))
  )

fit_dy_reg_g <- glance(fit_dy_reg) |> select(.model, AIC, AICc, BIC)
fit_auto_arima_g <- glance(fit_auto_arima) |> select(.model, AIC, AICc, BIC)
```



$$
(1 - \phi_{1}B -  \phi_{2}B^{2})(1 - \phi_{1}B^{12})(1- B^{12}) y_{t} = x_{temperature} +(1 + \theta_{1}B +  \theta_{2}B^{2})(1 + \theta_{1}B^{12})\epsilon_{t}
$$
Utilizing the forecasts generated for temperatures, we can generate forecasts for the monthly energy consumptions using this dynamic regression model as below. 



```{r}
fc1 <- forecast(fit_dy_reg, ontario_temps_fc_2years) 

fc1 |> autoplot(elec_demand) + 
    theme_ipsum() + labs(x = "Temperature (C)", y = "Monthly Demand (MW)", title ="2Y Forecasts with Dynamic Regression")
```



### Cross-Validation 

When we apply rolling-forecast-origin cross-validation to this time series, we find that the **dynamic regression model outperforms the AutoARIMA model in terms of error by 1 - 2%**. Although this error measurement captures only the training error, since using a separate testing set in time series cross-validation may lose valuable information, **Temperature proves to be a strong predictor for forecasting energy consumption in Ontario.**



```{r}
fc_acc <- rbind(accuracy(fit_dy_reg), accuracy(fit_auto_arima))
fc_acc |> 
  select(.model, MAE, RMSE, MAPE, RMSSE)

```


## Results

As we have demonstrated that including temperature as an explanatory variable improves the model, data on temperature changes could enhance the accuracy of forecasts for monthly energy consumption in Ontario. Additionally, **reliable and frequently updated expert temperature forecasts allow for adjustments in energy consumption predictions based on significant changes in future temperatures**.

Having accurate forecasts for energy consumption is crucial, as they can **inform planning for maintenance and repairs of electricity-generating facilities**. Moreover, if we have access to monthly supply data, information on energy storage, and costs associated with energy generation at specific times in Ontario, **this scenario could be framed as an optimization problem**. **Utilizing dynamic programming, we could optimize production and reduce costs for energy generation in the province**.

